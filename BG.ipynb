{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IMCn-4Aq0ar"
      },
      "outputs": [],
      "source": [
        "!pip install gensim &> /dev/null\n",
        "!pip install -U pip setuptools wheel &> /dev/null\n",
        "!pip install texthero &> /dev/null\n",
        "!pip install -U spacy &> /dev/null\n",
        "!pip install simplemma &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "#import texthero\n",
        "from re import sub\n",
        "import nltk\n",
        "from tqdm import tqdm\n",
        "import simplemma\n",
        "import gensim\n",
        "import pickle\n",
        "from gensim.models import Word2Vec\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "import csv\n",
        "import scipy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlrOSZ_Iq_m1",
        "outputId": "cf844057-52ca-436c-adfc-99f3c6f26247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STOP_WORDS = set(\n",
        "    \"\"\"\n",
        "а автентичен аз ако ала\n",
        "бе без беше би бивш бивша бившо бивши бил била били било благодаря близо бъдат\n",
        "бъде бъда бяха\n",
        "в вас ваш ваша вашата вашият вероятно вече взема ви вие винаги внимава време все \n",
        "всеки всички вместо всичко вследствие всъщност всяка втори във въпреки върху\n",
        "вътре веднъж \n",
        "г ги главен главна главно глас го годно година години годишен\n",
        "д да дали далеч далече два двама двамата две двете ден днес дни до добра добре \n",
        "добро добър достатъчно докато докога дори досега доста друг друга другаде други\n",
        "е евтин едва един една еднаква еднакви еднакъв едно екип ето\n",
        "живот жив\n",
        "за здравей здрасти знае зная забавям зад зададени заедно заради засега заспал \n",
        "затова запазва започвам защо защото завинаги\n",
        "и из или им има имат иска искам използвайки изглежда изглеждаше изглеждайки \n",
        "извън имайки\n",
        "й йо \n",
        "каза казва казвайки казвам как каква какво както какъв като кога кауза каузи \n",
        "когато когото което които кой който колко която къде където към край кратък \n",
        "кръгъл\n",
        "лесен лесно ли летя летиш летим лош\n",
        "м май малко макар малцина междувременно минус ме между мек мен месец ми мис \n",
        "мисля много мнозина мога могат може мой можем мокър моля момента му\n",
        "н на над назад най наш навсякъде навътре нагоре направи напред надолу наистина \n",
        "например наопаки наполовина напоследък нека независимо нас насам наскоро \n",
        "настрана необходимо него негов нещо нея ни ние никой нито нищо но нов някак нова \n",
        "нови новина някои някой някога някъде няколко няма\n",
        "о обаче около описан опитах опитва опитвайки опитвам определен определено освен \n",
        "обикновено осигурява обратно означава особен особено от ох отвъд отгоре отдолу \n",
        "отново отива отивам отидох отсега отделно отколкото откъдето очевидно оттам \n",
        "относно още\n",
        "п пак по повече повечето под поне просто пряко поради после последен последно \n",
        "посочен почти прави прав прави правя пред преди през при пък първата първи първо \n",
        "път пъти плюс\n",
        "равен равна различен различни разумен разумно\n",
        "с р са сам само себе сериозно сигурен сигурно се сега си син скоро скорошен след \n",
        "следващ следващия следва следното следователно случва сме смях собствен \n",
        "сравнително смея според сред става срещу съвсем съдържа съдържащ съжалявам \n",
        "съответен съответно сте съм със също\n",
        "т така техен техни такива такъв твърде там трета твой те тези ти то това \n",
        "тогава този той търси толкова точно три трябва тук тъй тя тях\n",
        "у утре ужасно употреба успоредно уточнен уточняване\n",
        "харесва харесали хиляди\n",
        "ч часа ценя цяло цялостен че често чрез чудя\n",
        "ще щеше щом щяха\n",
        "юмрук\n",
        "я як\n",
        "\"\"\".split()\n",
        ")"
      ],
      "metadata": {
        "id": "MXYtpHgYrVI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "corpus = []\n",
        "path = 'folds'\n",
        "processed_files = 0\n",
        "\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for file in tqdm(files):\n",
        "        if file.endswith('.txt'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            with open(file_path, 'r') as f:\n",
        "                text = f.read()\n",
        "                sentences = nltk.sent_tokenize(text)\n",
        "                corpus.extend(sentences)\n",
        "            processed_files += 1\n",
        "\n",
        "with open('sentences.txt', 'w') as f:\n",
        "    f.write('\\n'.join(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZf1i1BRrush",
        "outputId": "8fbab09d-451c-4205-a7c1-8427890d0000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 1636/1636 [01:03<00:00, 25.57it/s]\n",
            "100%|██████████| 29/29 [00:06<00:00,  4.21it/s]\n",
            "100%|██████████| 455/455 [00:05<00:00, 77.38it/s] \n",
            "100%|██████████| 1586/1586 [00:23<00:00, 67.20it/s] \n",
            "100%|██████████| 7359/7359 [03:20<00:00, 36.77it/s] \n",
            "100%|██████████| 652/652 [00:12<00:00, 54.12it/s] \n",
            "100%|██████████| 25256/25256 [14:05<00:00, 29.86it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_bg = []\n",
        "with open(r'sentences.txt') as file:\n",
        "    for line in file:\n",
        "        corpus_bg.append(line.rstrip())"
      ],
      "metadata": {
        "id": "uoV2LYacxONq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_bg[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9woggxzxaxR",
        "outputId": "c41ef6dd-c6d4-4bc1-f4f0-15e7faff3ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'ПРИЛОЖЕНИЕ I',\n",
              " '',\n",
              " 'КРАТКА ХАРАКТЕРИСТИКА НА ПРОДУКТА',\n",
              " '',\n",
              " '1 1.',\n",
              " 'ИМЕ НА ЛЕКАРСТВЕНИЯ ПРОДУКТ',\n",
              " '',\n",
              " 'Fendrix инжекционна суспензия.',\n",
              " 'Ваксина срещу хепатит B (р- ДНК) (Адсорбирана, с адювант) [ Hepatitis B (rDNA) vaccine (adjuvanted, adsorbed) ].',\n",
              " '2.',\n",
              " 'КАЧЕСТВЕН И КОЛИЧЕСТВЕН СЪСТАВ',\n",
              " '',\n",
              " 'Една доза (0, 5 ml) Fendrix съдържа:',\n",
              " '',\n",
              " 'Хепатит B повърхностен антиген 1, 2, 3 1 адювантен с AS04C съдържащ:',\n",
              " '',\n",
              " '20 микрограма',\n",
              " '',\n",
              " '- 3- O- дезацил- 4 ’ - монофосфорил липид A (MPL) 2 2 адсорбиран върху алуминиев фосфат (общо 0, 5 милиграма Al3+) 3']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text_list, stop_words):\n",
        "    # Remove elements with <> in them\n",
        "    text_list = [x for x in text_list if \"<\" not in x and \">\" not in x]\n",
        "    \n",
        "    # Make all elements lowercase\n",
        "    text_list = [x.lower() for x in text_list]\n",
        "    \n",
        "    # Get rid of punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    text_list = [x.translate(table) for x in text_list]\n",
        "    \n",
        "    # Get rid of double spaces\n",
        "    text_list = [re.sub(' +', ' ', x) for x in text_list]\n",
        "    \n",
        "    # Get rid of stopwords\n",
        "    text_list = [x for x in text_list if x not in STOP_WORDS]\n",
        "\n",
        "    text_list = [re.sub(r'\\d+', '', x) for x in text_list]\n",
        "    \n",
        "    return text_list\n",
        "\n",
        "preprocessed_text = preprocess_text(corpus_bg, STOP_WORDS)\n",
        "preprocessed_text[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0PRdB8kxk0o",
        "outputId": "752da1e9-87bf-4c2c-b2f7-fdd1b09333d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'приложение i',\n",
              " '',\n",
              " 'кратка характеристика на продукта',\n",
              " '',\n",
              " ' ',\n",
              " 'име на лекарствения продукт',\n",
              " '',\n",
              " 'fendrix инжекционна суспензия',\n",
              " 'ваксина срещу хепатит b р днк адсорбирана с адювант hepatitis b rdna vaccine adjuvanted adsorbed ',\n",
              " '',\n",
              " 'качествен и количествен състав',\n",
              " '',\n",
              " 'една доза   ml fendrix съдържа',\n",
              " '',\n",
              " 'хепатит b повърхностен антиген     адювантен с asc съдържащ',\n",
              " '',\n",
              " ' микрограма',\n",
              " '',\n",
              " '  o дезацил  ’ монофосфорил липид a mpl   адсорбиран върху алуминиев фосфат общо   милиграма al ']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_text = []\n",
        "romanian_numbers = [\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"]\n",
        "\n",
        "for line in preprocessed_text:\n",
        "    words = line.split()\n",
        "    stemmed_line = []\n",
        "    for word in words:\n",
        "        normalized_word = simplemma.lemmatize(word, lang='bg')\n",
        "        stemmed_line.append(normalized_word)\n",
        "    lemmatized_text.append(\" \".join(stemmed_line))\n",
        "\n",
        "lemmatized_text = [s.replace(\"»\", \"\").replace(\"«\", \"\") for s in lemmatized_text if s.strip()]\n",
        "\n",
        "# Regular expression pattern to match English letters\n",
        "english_pattern = re.compile(r'[a-zA-Z]')\n",
        "\n",
        "lemmatized_text = [re.sub(r'\\b\\d+\\b', '', string) for string in lemmatized_text if string not in romanian_numbers]\n",
        "lemmatized_text = [string for string in lemmatized_text if not english_pattern.search(string)]\n",
        "\n",
        "# Print the lemmatized text\n",
        "print(lemmatized_text[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K76accA2yRaE",
        "outputId": "9e9e0781-e95b-44ce-bc9f-84c9092c4b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['кратък характеристика на продукт', 'име на лекарствен продукт', 'качествен и количествен състав', 'микрограм', 'микрограм', 'за пълен списък на помощните вещество вж', 'точка', 'лекарствен форма', 'инжекционна суспензия', 'мътен бял суспензия', 'при съхраня мога да се наблюдавам образуване на фин бял утайка с бистър безцветен надутаечен слой', 'клинични данни', 'терапевтични покажа', 'дозировка и начин на приложение', 'дозировка', 'схема за първичен ваксинация', 'препоръчвам се схема с прилагане на четири доза като имунизирането съм на избран дата месец месец и месец след прилагане на първи доза', 'бустер доза', 'начин на приложение', 'противопокажа']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_list_to_csv(list_, file_name):\n",
        "    with open(file_name, 'w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        for row in list_:\n",
        "            writer.writerow([row])\n",
        "save_list_to_csv(lemmatized_text, 'stemmed_text_bg_new.csv')"
      ],
      "metadata": {
        "id": "nXao6-CIycgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_corp= pd.read_csv('stemmed_text_bg_new.csv',header=None, names=['text'])"
      ],
      "metadata": {
        "id": "sIARUTXuynG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_corp = stem_corp[stem_corp['text'].str.split().str.len() >= 4]"
      ],
      "metadata": {
        "id": "FTlF55wn1hIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stem_corp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wKfHq1cyyq3z",
        "outputId": "44812e77-93fe-4f85-de56-26e2d92e0bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                      text\n",
              "0                         кратък характеристика на продукт\n",
              "1                                име на лекарствен продукт\n",
              "2                           качествен и количествен състав\n",
              "5                 за пълен списък на помощните вещество вж\n",
              "10       при съхраня мога да се наблюдавам образуване н...\n",
              "...                                                    ...\n",
              "1003848  Македония и Албания ща съм сътруднича в гранич...\n",
              "1003849  организиран с подкрепа на нато инициатива ща п...\n",
              "1003850  ръководител на отдел на нато за балкан робърт ...\n",
              "1003851  върховен представител пади ашдаун заявя пред р...\n",
              "1003852                                 уебсайт на свп пбс\n",
              "\n",
              "[799699 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b37146e-d2fa-4e69-864c-4bdaf1371d1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>кратък характеристика на продукт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>име на лекарствен продукт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>качествен и количествен състав</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>за пълен списък на помощните вещество вж</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>при съхраня мога да се наблюдавам образуване н...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003848</th>\n",
              "      <td>Македония и Албания ща съм сътруднича в гранич...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003849</th>\n",
              "      <td>организиран с подкрепа на нато инициатива ща п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003850</th>\n",
              "      <td>ръководител на отдел на нато за балкан робърт ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003851</th>\n",
              "      <td>върховен представител пади ашдаун заявя пред р...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1003852</th>\n",
              "      <td>уебсайт на свп пбс</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>799699 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b37146e-d2fa-4e69-864c-4bdaf1371d1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b37146e-d2fa-4e69-864c-4bdaf1371d1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b37146e-d2fa-4e69-864c-4bdaf1371d1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(min_df=5)\n",
        "\n",
        "data_vectorized = vectorizer.fit_transform(stem_corp['text'][5000::10])"
      ],
      "metadata": {
        "id": "N0-LqoNbzFy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = data_vectorized.toarray()\n",
        "A = A.astype(float)"
      ],
      "metadata": {
        "id": "380oO6co0PWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = sorted(vectorizer.vocabulary_.keys())"
      ],
      "metadata": {
        "id": "rFBcZrQH0Sc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdvEILuI0T-E",
        "outputId": "6cdff38e-07fd-493d-dadd-6450c42291a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11540"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_vTxVO-255G",
        "outputId": "b5eb99a9-62ac-493a-eddf-b28a02d063e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79470, 11540)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K = 10\n",
        "u, s, vt = scipy.sparse.linalg.svds(A.T, k=K)"
      ],
      "metadata": {
        "id": "4z8qwCdP2-I4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A.T.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQewaK8F3EEy",
        "outputId": "920a77b3-70b1-4084-951f-b9b2811d3448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11540, 79470)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u.shape, s.shape, vt.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97PeVvx3FfL",
        "outputId": "24d95e32-42e2-4119-dbbb-be4d015d14cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11540, 10), (10,), (10, 79470))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bg_vt_' + str(K) +  '.pickle', 'wb') as f:\n",
        "  pickle.dump(vt, f)\n",
        "with open('bg_u_' + str(K) + '.pickle', 'wb') as f:\n",
        "  pickle.dump(u, f)\n",
        "with open('bg_s_.' + str(K) + 'pickle', 'wb') as f:\n",
        "  pickle.dump(s, f)"
      ],
      "metadata": {
        "id": "EZTmbeMy3HPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_names[20:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ved5gyFb3hfZ",
        "outputId": "2cbb90bf-81cf-477e-8a80-ccdaf8ae09bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['абдулах', 'абк', 'абнормен', 'абнормна', 'абнормни', 'абнормно', 'абонат', 'аборт', 'аборти', 'абортите', 'абсолютен', 'абсолютно', 'абсорбирам', 'абсорбция', 'абстиненция', 'абсурден', 'абсцес', 'ав', 'аваз', 'август', 'авив', 'авиокомпания', 'авиолиния', 'авоарите', 'австралийски', 'австралия', 'австриец', 'австрийски', 'австрия', 'австроунгарски']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect >> None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp1GohmK5CwY",
        "outputId": "40921129-5089-4840-9d2b-2df47d88b79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from langdetect import detect\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Detect language of the text\n",
        "    lang = detect(text)\n",
        "    # Remove punctuation and convert to lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "    # Tokenize the text\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stop words and words in English and Greek\n",
        "    if lang == 'bg':\n",
        "        stop_words = STOP_WORDS\n",
        "    else:\n",
        "        stop_words = STOP_WORDS.union(set(word_tokenize(' '.join(stopwords.words(lang)))))\n",
        "\n",
        "    tokens = [token for token in tokens if token not in stop_words and not any(char in string.ascii_letters for char in token)]\n",
        "    # Perform morphological analysis and lemmatization\n",
        "    lemmatized_tokens = []\n",
        "    for token in tokens:\n",
        "        lemma = simplemma.lemmatize(token, lang=lang)\n",
        "        lemmatized_tokens.append(lemma)\n",
        "    # Join the preprocessed tokens back into a single string\n",
        "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "def convertTextToEmbeddingSeries(text, dict_words, emb):\n",
        "    wtext = preprocess_text(text)\n",
        "    wdata = wtext.split(' ')\n",
        "    word2ind = dict(zip(dict_words, np.arange(len(dict_words))))\n",
        "    embText = []\n",
        "    for word in wdata:\n",
        "        ind = word2ind.get(word)\n",
        "        if ind: embText.append(emb[ind])\n",
        "    return np.array(embText)"
      ],
      "metadata": {
        "id": "_mL3ws9r3q24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_text = preprocess_text('организиран с подкрепа на нато инициатива ща')\n",
        "preprocessed_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "TsK_Dk8S3uUI",
        "outputId": "786f7b9d-4f30-4278-8a18-c22eecab1884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'организирам подкрепа нато инициатива ща'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textSeries = convertTextToEmbeddingSeries(preprocessed_text,\n",
        "                                          feature_names,\n",
        "                                          u)"
      ],
      "metadata": {
        "id": "dIRDf-NV5cfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textSeries.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBEh8Rwy5lkL",
        "outputId": "e47fafab-a1d6-4d7c-8052-a62e8c8753b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textSeries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BKVBPad5nAa",
        "outputId": "08a7c09b-c9c6-4720-e572-097a582d06ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.05386215e-04,  2.52836735e-04,  1.88880391e-04,\n",
              "         1.29095354e-03,  1.86181262e-03,  3.27577801e-04,\n",
              "         2.06188861e-04,  1.17232112e-03, -6.37433036e-04,\n",
              "        -1.10048655e-03],\n",
              "       [ 1.04532651e-03, -2.60634074e-03,  1.65438937e-04,\n",
              "         4.31073947e-03,  8.98719318e-03, -9.17829061e-04,\n",
              "         5.68939917e-03,  1.13627826e-02, -9.88337586e-04,\n",
              "        -6.59270644e-03],\n",
              "       [ 1.85782742e-04, -8.44670433e-03, -1.66386780e-03,\n",
              "         9.98367580e-03,  1.19292952e-02, -4.29382379e-03,\n",
              "         5.91022888e-03,  7.83156737e-03, -2.90202188e-04,\n",
              "        -8.55594902e-03],\n",
              "       [-2.36933377e-03,  7.27782687e-04,  6.92567807e-04,\n",
              "         1.54191652e-03,  1.97946816e-03,  3.27364123e-04,\n",
              "         1.22075155e-03,  2.13434742e-03, -3.08917544e-04,\n",
              "        -1.84925066e-03],\n",
              "       [-1.00441914e-02, -2.58634779e-01, -2.85811231e-02,\n",
              "         1.02404900e-01,  1.06312855e-01,  2.08094046e-02,\n",
              "         1.95244851e-02,  4.23311675e-02, -2.72297058e-02,\n",
              "        -4.31999434e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    }
  ]
}